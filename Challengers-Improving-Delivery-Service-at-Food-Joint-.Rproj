# Install and load required libraries
install.packages("dplyr")
library(dplyr)

# Read data from CSV file
data <- read.csv("data/finalTrain.csv")

# Check first few rows of the data
head(data, 3)

# Check rows with missing values in "Delivery_person_Age"
head(data[is.na(data$Delivery_person_Age)], 3)

# Check the data types and number of non-null values for each column
summary(data)

# Drop columns with no information or unique values
data <- data %>% select(-Delivery_person_ID, -Delivery_person_ID, -ID, -Time_Orderd, -Time_Order_picked)

# Check the data types and number of non-null values for each column after dropping columns
summary(data)

# Check first few rows of the data after dropping columns
head(data, 3)

# Import required libraries
library(matplotlib.pyplot)
library(seaborn)

# Define a function to plot histograms with density curves
histplotcount_func <- function(input_feature, data, no_of_bins) {
  ggplot(data, aes(x = input_feature)) +
    geom_histogram(bins = no_of_bins) +
    stat_density(geom = "line", color = "blue") +
    labs(title = paste("Distribution of", input_feature), x = input_feature, y = "Frequency") +
    theme_bw()

  # Show the plot
  print(ggplot2::last_plot())
}

# Plot histogram with density curve for "Delivery_person_Age"
histplotcount_func("Delivery_person_Age", data, 5)

# Calculate the mean of "Delivery_person_Age" to fill missing values
mean_age <- mean(data$Delivery_person_Age)

# Fill missing values in "Delivery_person_Age" with the mean
data$Delivery_person_Age <- replace(data$Delivery_person_Age, is.na(data$Delivery_person_Age), mean_age)

# Check the distribution of "Delivery_person_Ratings"
data$Delivery_person_Ratings %>% count()

# Remove rows where "Delivery_person_Ratings" is 6
data <- data %>% filter(Delivery_person_Ratings != 6)

# Plot histogram with density curve for "Delivery_person_Ratings"
histplotcount_func("Delivery_person_Ratings", data, 5)

# Loop through each column in the DataFrame and print information about each column
for (i in colnames(data)) {
  print(paste0("Column Name: ", i))
  print(paste0("Column Type: ", typeof(data[[i]])))
  print(rep("=", 64))

  # Print unique values in the column
  unique_values <- unique(data[[i]])
  print(unique_values)
  print(rep("=", 64))
}

# Count the number of records with zero values in "Delivery_location_latitude"
count_zero_longitude <- sum(data$Delivery_location_latitude == "0")
print(paste0("Number of records with Delivery_location_latitude equal to 0: ", count_zero_longitude))

# Count the number of records with zero values in "Restaurant_latitude"
count_zero_latitude <- sum(data$Restaurant_latitude == 0)
print(paste0("Number of records with Restaurant_latitude equal to 0: ", count_zero_latitude))

# Count the number of records with zero values in "Restaurant_longitude"
count_zero_longitude <- sum(data$Restaurant_longitude == 0)
print(paste0("Number of records with Restaurant_longitude equal to 0: ", count_zero_longitude))

# Plot histogram with density curve for "Restaurant_latitude"
histplotcount_func("Restaurant_latitude", data, 5)

# Plot histogram with density curve for "Restaurant_longitude"
histplotcount_func("Restaurant_longitude", data, 5)

# Check the data types and number of non-null values for each column again
summary(data)

# Calculate the median of "Delivery_location_longitude" to fill missing values
median_Delivery_location_longitude <- median(data$Delivery_location_longitude)

# Fill missing values in "Delivery_location_longitude" with the median
data$Delivery_location_longitude <- replace(data$Delivery_location_longitude, is.na(data$Delivery_location_longitude), median_Delivery_location_longitude)

# Calculate the median of "Delivery_location_latitude" to fill missing values
median_Delivery_location_latitude <- median(data$Delivery_location_latitude)

# Fill missing values in "Delivery_location_latitude" with the median
data$Delivery_location_latitude <- replace(data$Delivery_location_latitude, is.na(data$Delivery_location_latitude), median_Delivery_location_latitude)

# Check for duplicate rows
duplicate_rows <- data[duplicated(data)]

# Check the number of rows with and without duplicates
data.shape

# Calculate the percentage of rows with duplicates
percentage_duplicates <- (data.shape[0] - without_nan[0]) / data.shape[0] * 100
print(paste0("Percentage of rows with duplicates: ", round(percentage_duplicates, 2), "%"))

# Calculate the percentage of missing values in the dataset
missing_values_percentage <- (with_nan[0] - without_nan[0]) / with_nan[0] * 100
print(paste0("Percentage of missing values in the dataset: ", round(missing_values_percentage, 2), "%"))

# Calculate the percentage of valid data in the dataset
valid_data_percentage <- 100 - missing_values_percentage
print(paste0("Percentage of valid data in the dataset: ", round(valid_data_percentage, 2), "%"))

# Calculate the conversion rate
conversion_rate <- (2938 / 42646) * 100
print(paste0("Conversion rate: ", round(conversion_rate, 2), "%"))

# Check the data types and number of non-null values for each column again
summary(data)

# Check the first few rows of the "Order_Date" column
data[['Order_Date']].head()

# Check the unique values in "Order_Date"
unique(data$Order_Date)

# Extract the day from the "Order_Date" column and store it in a new column named "Day"
data["Day"] <- as.Date(data$Order_Date, "%d-%m-%Y") %>% ISOdate() %>% as.numeric()

# Check the first few rows of the data after extracting the day
data.head()

# Extract the month from the "Order_Date" column and store it in a new column named "Month"
data["Month"] <- as.Date(data$Order_Date, "%d-%m-%Y") %>% month()

# Extract the year from the "Order_Date" column and store it in a new column named "Year"
data["Year"] <- as.Date(data$Order_Date, "%d-%m-%Y") %>% year()

# Check the first few rows of the data after extracting the month and year
data[["Order_Date"]].head()

# Drop the "Order_Date" column since the information has been extracted into separate columns
data <- data %>% select(-Order_Date)

# Check the first few rows of the data after dropping the "Order_Date" column
data.head(3)

# Check the data types and number of non-null values for each column again
summary(data)

# Rename columns for better readability
names(data) <- c("Delivery_person_ID", "Delivery_person_Ratings", "multiple_deliveries",
                  "Restaurant_ID", "Restaurant_latitude", "Restaurant_longitude",
                  "Delivery_location_latitude", "Delivery_location_longitude",
                  "Road_traffic_density", "Weather_conditions", "Festival", "City",
                  "Day_Ordered", "Month_Ordered", "Year_Ordered", "Time_taken_min")

# Define a function to segregate categorical and numerical columns
column_segregator <- function(data, categorical_columns_list, numerical_columns_list) {
  for (col in colnames(data)) {
    if (is.character(data[[col]])) {
      categorical_columns_list <- append(categorical_columns_list, col)
    } else {
      numerical_columns_list <- append(numerical_columns_list, col)
    }
  }
}

# Initialize empty lists to store categorical and numerical columns
categorical_columns <- list()
numerical_columns <- list()

# Segregate categorical and numerical columns using the custom function
column_segregator(data, categorical_columns, numerical_columns)

# Print the identified categorical and numerical columns
print("Categorical Columns:")
print(categorical_columns)
print("\nNumerical Columns:")
print(numerical_columns)

# Describe the categorical columns using summary()
data[categorical_columns] %>% summary()

# Describe the numerical columns using describe() and transpose the result
data[numerical_columns] %>% describe() %>% t()

# Check for numeric values in categorical columns
for (column in categorical_columns) {
  if (grepl("[0-9]", data[[column]])) {
    print(paste0("Numeric values found in categorical column:", column))
  } else {
    print(paste0("No numeric values found in categorical column:", column))
  }
}

# Filter rows that don't contain ":" (i.e., rows with floating-point values) for "Time_Orderd"
filtered_rows <- data %>% filter(!is.na(Time_Orderd) & !grepl(":", Time_Orderd))

# Sort rows based on "Time_Orderd" column
sorted_rows <- filtered_rows %>% arrange(Time_Orderd)

# Retrieve only the "Time_Orderd" column values
result <- data.frame(Time_Orderd = sorted_rows$Time_Orderd)

# Count the occurrences of each unique value in the resulting column
value_counts <- result$Time_Orderd %>% value_counts()

# Display the value counts
print(value_counts, "\nSum =", sum(value_counts))

# Filter rows that don't contain ":" (i.e., rows with floating-point values) for "Time_Order_picked"
filtered_rows <- data %>% filter(!is.na(Time_Order_picked) & !grepl(":", Time_Order_picked))

# Sort rows based on "Time_Order_picked" column
sorted_rows <- filtered_rows %>% arrange(Time_Order_picked)

# Retrieve only the "Time_Order_picked" column values
result <- data.frame(Time_Order_picked = sorted_rows$Time_Order_picked)

# Count the occurrences of each unique value in the resulting column
value_counts <- result$Time_Order_picked %>% value_counts()

# Display the value counts
print(value_counts, "\nSum =", sum(value_counts))

# Calculate the correlation matrix using only numerical columns
correlation_matrix <- cor(data[numerical_columns], method = "spearman")

# Set up the figure and axes
plot(correlation_matrix, col = colorRamp("coolwarm"), main = "Correlation Heatmap")

# Add a title
text(0, 0.5, "Correlation Matrix", cex = 0.8, adj = c(0.5, 0.5))

# Show the plot
plot(correlation_matrix)

# Print the categorical columns
print("Categorical Columns:")
print(categorical_columns)

# Define a function to create bar plots with standard deviation error bars
barplot_func <- function(data, input_feature, output_feature) {
  ggplot(data, aes_string(x = input_feature, y = output_feature)) +
    geom_bar() +
    geom_errorbar(aes(ymin = output_feature - sd(output_feature), ymax = output_feature + sd(output_feature))) +
    labs(title = paste(output_feature, "by", input_feature), x = input_feature, y = output_feature) +
    theme_bw()

  print("\n")
  print(ggplot2::last_plot())
}

# Create a bar plot of "Time_taken(min)" by "Weather_conditions"
barplot_func(data, "Weather_conditions", "Time_taken_min")

# Get unique values in "Weather_conditions"
unique_weather_conditions <- unique(data$Weather_conditions)

# Create a dictionary to map weather conditions to numerical values
Weather_conditions_map <- c(
  Fog = 1,
  Cloudy = 2,
  Windy = 3,
  Sandstorms = 4,
  Stormy = 5,
  Sunny = 6
)  # (Least likely to cause delays)

# Replace weather conditions with corresponding numerical values
data$Weather_conditions <- sapply(data$Weather_conditions, function(x) Weather_conditions_map[[x]])

# Get unique values in "Road_traffic_density"
unique_traffic_density <- unique(data$Road_traffic_density)

# Create a dictionary to map traffic density to numerical values
Road_traffic_density_map <- c(
  Jam = 1,
  High = 2,
  Medium = 3,
  Low = 4
)

# Replace traffic density with corresponding numerical values
data$Road_traffic_density <- sapply(data$Road_traffic_density, function(x) Road_traffic_density_map[[x]])

# Create a bar plot of "Time_taken(min)" by "Type_of_vehicle"
barplot_func(data, "Type_of_vehicle", "Time_taken_min")

# Get unique values in "Type_of_vehicle"
unique_vehicle_types <- unique(data$Type_of_vehicle)

# Create a dictionary to map vehicle types to numerical values
Type_of_vehicle_map <- c(
  motorcycle = 1,
  scooter = 2,
  electric_scooter = 3
)

# Replace vehicle types with corresponding numerical values
data$Type_of_vehicle <- sapply(data$Type_of_vehicle, function(x) Type_of_vehicle_map[[x]])

# Create a bar plot of "Time_taken(min)" by "City"
barplot_func(data, "City", "Time_taken_min")

# Get unique values in "City"
unique_cities <- unique(data$City)

# Create a dictionary to map city types to numerical values
City_map <- c(
  Urban = 3,
  Metropolitian = 2,
  Semi_Urban = 1
)

# Replace city types with corresponding numerical values
data$City <- sapply(data$City, function(x) City_map[[x]])

# Create a list of the mapping dictionaries' keys
mapping_dicts_keys <- names(mapping_dicts)

# Map values using the mapping dictionaries
for (column in mapping_dicts_keys) {
  data[[column]] <- as.numeric(sapply(data[[column]], function(x) mapping_dicts[[column]][[x]]))
}

# Define a function to perform one-hot encoding for a categorical column in a DataFrame
one_hot_encoder_func <- function(data, column_name) {
  # Validate inputs
  if (!is.data.frame(data)) {
    stop("Input 'data' must be a data.frame.")
  }

  if (!column_name %in% colnames(data)) {
    stop(paste0("Column '", column_name, "' not found in the data.frame."))
  }

  # Perform one-hot encoding
  one_hot_encoded <- data[[column_name]] %>% as.factor() %>% levels() %>% do.call(data.frame, .) %>% setNames(paste0(column_name, "_"))

  # Concatenate the one-hot encoded columns with the original DataFrame
  data <- data %>% cbind(one_hot_encoded)

  # Drop the original column
  data <- data %>% select(-column_name)

  return(data)
}

# Check the first few rows of the data
data[1:3,]

# Get unique values in "Type_of_order"
unique_order_types <- unique(data$Type_of_order)

# Perform one-hot encoding for "Type_of_order"
data <- one_hot_encoder_func(data, "Type_of_order")

# Perform one-hot encoding for "Festival"
data <- one_hot_encoder_func(data, "Festival")

# Check the first few rows of the data after one-hot encoding
data[1:3,]

# Define a function to create a line plot with a KDE curve
lineplot_with_kde <- function(input_feature, output_feature, data) {
  ggplot(data, aes_string(x = input_feature, y = output_feature)) +
    geom_line(color = "blue", label = "Line Plot") +
    geom_density2d(cmap = "Reds", label = "KDE", shade = TRUE) +
    labs(title = paste("Line Plot with KDE of", output_feature, "based on", input_feature), x = input_feature, y = output_feature) +
    theme_bw()

  print("\n")
  print(ggplot2::last_plot())
}

# Target column for line plots
target_col <- "Time_taken_min"

# Create line plots with KDE curves for various features
lineplot_with_kde("Delivery_person_Age", target_col, data)
lineplot_with_kde("Delivery_person_Ratings", target_col, data)
lineplot_with_kde("Weather_conditions", target_col, data)
lineplot_with_kde("Vehicle_condition", target_col, data)

# Print the Weather_conditions_map dictionary
print(Weather_conditions_map)

# Calculate the correlation matrix using only numerical columns
correlation_matrix <- cor(data[numerical_columns], method = "spearman")

# Set up the figure and axes
plot(correlation_matrix, col = colorRamp("coolwarm"), main = "Correlation Heatmap")

# Add a title
text(0, 0.5, "Correlation Matrix", cex = 0.8, adj = c(0.5, 0.5))

# Show the plot
plot(correlation_matrix)

# Create bar plots for additional features
barplot_func(data, "multiple_deliveries", target_col)
barplot_func(data, "Festival_Yes", target_col)
barplot_func(data, "City", target_col)

# Print the City_map dictionary
print(City_map)

# Create bar plots for relationships between features
barplot_func(data, "Delivery_person_Ratings", "Delivery_person_Age")
barplot_func(data, "multiple_deliveries", "Delivery_person_Age")
barplot_func(data, "multiple_deliveries", "Road_traffic_density")

# Print the Road_traffic_density_map dictionary
print(Road_traffic_density_map)

# Create additional bar plots for relationships between features
barplot_func(data, "Festival_Yes", "Road_traffic_density")
barplot_func(data, "City", "Road_traffic_density")

# Print the City_map dictionary
print(City_map)

# Create bar plots for vehicle-related relationships
barplot_func(data, "Type_of_vehicle", "Vehicle_condition")
barplot_func(data, "Festival_Yes", "multiple_deliveries")
barplot_func(data, "Festival_Yes", "multiple_deliveries")

# Define a function to create custom pair bar plots
custom_pairbarplot <- function(data, columns_to_compare, input_column_type, output_column, type_of_plot) {
  # Grouping and summing each order type based on festival status
  grouped <- data %>% group_by(output_column) %>% summarise(across(columns_to_compare, sum))

  # Plotting the bar plots
  ggplot(grouped, aes_string(x = output_column, y = !columns_to_compare[1])) +
    geom_bar() +
    labs(title = paste0("Comparison of", input_column_type, "for", output_column, "Status"), x = output_column, y = "Sum Count") +
    theme_bw()

  print("\n")
  print(ggplot2::last_plot())
}

# Define variables for first bar plot
columns_to_compare <- c("Type_of_order_Buffet", "Type_of_order_Drinks", "Type_of_order_Meal", "Type_of_order_Snack")
input_column_type <- "Order_Type"
output_column <- "City"
type_of_plot <- "bar"

# Create a custom pair bar plot
custom_pairbarplot(data, columns_to_compare, input_column_type, output_column, type_of_plot)

# Print the City_map dictionary
print(City_map)

# Define variables for second bar plot
columns_to_compare <- c("Type_of_order_Buffet", "Type_of_order_Drinks", "Type_of_order_Meal", "Type_of_order_Snack")
input_column_type <- "Order_Type"  # Update to reflect the actual x-axis label you want
output_column <- "Festival_Yes"
type_of_plot <- "bar"

# Create a custom pair bar plot
custom_pairbarplot(data, columns_to_compare, input_column_type, output_column, type_of_plot)

# Calculate the correlation matrix
correlation_matrix <- cor(data)

# Set up the figure and axes
plot(correlation_matrix, col = colorRamp("coolwarm"), main = "Correlation Heatmap")

# Add a title
text(0, 0.5, "Correlation Matrix", cex = 0.8, adj = c(0.5, 0.5))

# Show the plot
plot(correlation_matrix)

# Get unique values in "City"
unique_cities <- unique(data$City)

# Save the DataFrame as a CSV file
data %>% write_csv("cleaned_data.csv", row.names = FALSE)